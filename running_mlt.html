<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multiclass Classifier Training Agent - WhiteLightning</title>
    <link rel="stylesheet" href="styles/running_mlt.css">
</head>
<body>
    <header class="wl-header">
        <div class="logo">
          <img src="media/image/moonshiner_floppy.jpeg" alt="WhiteLightning Logo">
          <h1><a href="index.html" style="text-decoration: none;letter-spacing: 0px; color: inherit; ">White<span>Lightning</span></a></h1>
        </div>
        <div class="hamburger">
          <span></span>
          <span></span>
          <span></span>
        </div>
        <nav>
          <ul>
            <li><a  href="playground.html">Playground</a></li>
            <li><a  id="plgr_btn" href="docs.html">Getting Started</a></li>
            <li><a href="https://github.com/volodymyrparanyak/whitelightning.ai" target="_blank">GitHub</a></li>
          </ul>
        </nav>
      </header>

    <div class="docs-container">
        <div class="docs-sidebar">
            <nav class="docs-nav">
              <ul>
                <li><a href="docs.html">Overview</a>
                  <ul style="margin-left:1.2em;">
                    <li><a href="docs.html#what-is-llm">What is LLM Distillation?</a></li>
                    <li><a href="docs.html#why-onnx">Why ONNX?</a></li>
                    <li><a href="docs.html#features">Key Features</a></li>
                    <li><a href="docs.html#quick-start">Quick Start</a></li>
                    <li><a href="docs.html#documentation">Deployment Guide</a></li>
                  </ul>
                </li>
                <li><a href="#model-types">Model Types</a>
                  <ul style="margin-left:1.2em;">
                    <li><a href="binary-classifier.html">Binary Classifier</a></li>
                    <li><a href="multiclass-classifier.html">Multiclass Classifier</a>
                      <ul style="margin-left:1.2em;">
                        <li><a href="#running-multiclass-models">Running Multiclass Classifier Models</a></li>
                      </ul>
                    </li>
                  </ul>
                </li>
                
              </ul>
            </nav>
          </div>

        <main class="docs-content">
            <section id="running-multiclass-models">
                <h1 class="neon-green">Running Multiclass Classifier Models</h1>
                <div class="terminal-container intro-terminal">
                    <div class="terminal-header">
                        <div class="terminal-buttons">
                            <span class="terminal-circle red"></span>
                            <span class="terminal-circle yellow"></span>
                            <span class="terminal-circle green"></span>
                        </div>
                        <div class="terminal-title">WhiteLightning.ai Intro</div>
                    </div>
                    <div class="terminal-intro"><span id="typewriter-intro"></span></div>
                </div>
                
                <div class="process-cards">
                    <div class="process-card">
                        <h2 class="neon-green">üîÑ Preprocessing: Tokenizing the Text</h2>
                        <div class="process-steps">
                            <div class="step">
                                <span class="step-number">1</span>
                                <div class="step-content">
                                    <h4>Text Input</h4>
                                    <p>Start with a string (e.g., "The government announced new policies")</p>
                                </div>
                            </div>
                            <div class="step">
                                <span class="step-number">2</span>
                                <div class="step-content">
                                    <h4>Tokenization</h4>
                                    <p>Convert words to lowercase and map them to integer IDs using a tokenizer vocabulary (from <code>_tokenizer.json</code>). Unknown words use the <code>&lt;OOV&gt;</code> token (default ID: 1)</p>
                                </div>
                            </div>
                            <div class="step">
                                <span class="step-number">3</span>
                                <div class="step-content">
                                    <h4>Padding/Truncation</h4>
                                    <p>Truncate to 30 tokens and pad with zeros to ensure a fixed-length sequence</p>
                                </div>
                            </div>
                            <div class="step">
                                <span class="step-number">4</span>
                                <div class="step-content">
                                    <h4>Output</h4>
                                    <p>A 30-element <code>int32</code> array, ready for the ONNX model</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="process-card">
                        <h2 class="neon-green">ü§ñ Inference: Classifying the Text</h2>
                        <div class="process-steps">
                            <div class="step">
                                <span class="step-number">1</span>
                                <div class="step-content">
                                    <h4>Model Loading</h4>
                                    <p>Load the ONNX model (<code>news_classifier.onnx</code>) using the ONNX Runtime</p>
                                </div>
                            </div>
                            <div class="step">
                                <span class="step-number">2</span>
                                <div class="step-content">
                                    <h4>Inference</h4>
                                    <p>Pass the <code>[1, 30]</code> <code>int32</code> tensor to the model, which outputs a softmax probability distribution over classes</p>
                                </div>
                            </div>
                            <div class="step">
                                <span class="step-number">3</span>
                                <div class="step-content">
                                    <h4>Label Mapping</h4>
                                    <p>Load the label map (from <code>_scaler.json</code>) to convert the highest-probability index to a class name (e.g., "Politics")</p>
                                </div>
                            </div>
                            <div class="step">
                                <span class="step-number">4</span>
                                <div class="step-content">
                                    <h4>Output</h4>
                                    <p>The predicted class and its probability score (e.g., "Politics (Score: 0.9123)")</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- <section id="onnx-demos">
                <h2 class="neon-green">üì± ONNX Model Deployment Demos</h2>
                <h3 class="neon-green">ü§ñ Android</h3>
                <p>üé¨ <strong>Demo: ONNX inference running on Android device</strong></p>
                <p align="center">
                   <img src="media/Android runningONNX.gif" width="200" alt="CLI Usage">
                </p>
                <p>üîó <a class="neon-link" href="https://www.youtube.com/watch?v=ANDROID_VIDEO_ID" target="_blank">Watch Full Video on YouTube</a></p>
                <h3 class="neon-green">üçé iOS</h3>
                <p>üé¨ <strong>Demo: ONNX model working in an iOS app (Swift + CoreML)</strong></p>
                <p align="center">
                   <img src="media/OIS runningONNX.gif" width="700" alt="CLI Usage">
                </p>
                <p>üîó <a class="neon-link" href="https://www.youtube.com/watch?v=IOS_VIDEO_ID" target="_blank">Watch iOS Deployment on YouTube</a></p>
            </section> -->

            <section id="code-examples">
                <h2 class="neon-green">üíª Code Examples</h2>
                <div class="terminal-container">
                    <div class="terminal-header">
                        <div class="terminal-buttons">
                            <span class="terminal-circle red"></span>
                            <span class="terminal-circle yellow"></span>
                            <span class="terminal-circle green"></span>
                        </div>
                        <div class="terminal-title">WhiteLightning.ai ONNX Runner</div>
                    </div>
                    <div class="terminal-intro"><span id="typewriter"></span></div>
                    <div class="language-selector">
                        <button class="lang-btn active" data-lang="python">Python</button>
                        <button class="lang-btn" data-lang="javascript">JavaScript</button>
                        <button class="lang-btn" data-lang="c">C</button>
                        <button class="lang-btn" data-lang="cpp">C++</button>
                        <button class="lang-btn" data-lang="rust">Rust</button>
                        <button class="lang-btn" data-lang="java">Java</button>
                    </div>
                    <div class="terminal-content">
                        <div class="code-block active" id="python-code">
                            <pre><code><span class="prompt">$</span> <span class="keyword">import</span> <span class="module">json</span>
<span class="keyword">import</span> <span class="module">numpy</span> <span class="keyword">as</span> <span class="module">np</span>
<span class="keyword">import</span> <span class="module">onnxruntime</span> <span class="keyword">as</span> <span class="module">ort</span>

<span class="keyword">def</span> <span class="function">preprocess_text</span>(<span class="parameter">text</span>, <span class="parameter">tokenizer_file</span>):
    <span class="keyword">with</span> <span class="function">open</span>(tokenizer_file, <span class="string">'r'</span>) <span class="keyword">as</span> f:
        tokenizer = <span class="module">json</span>.<span class="function">load</span>(f)
    
    oov_token = <span class="string">'&lt;OOV&gt;'</span>
    words = text.<span class="function">lower</span>().<span class="function">split</span>()
    sequence = [tokenizer.<span class="function">get</span>(word, tokenizer.<span class="function">get</span>(oov_token, <span class="number">1</span>)) <span class="keyword">for</span> word <span class="keyword">in</span> words]
    sequence = sequence[:<span class="number">30</span>]  <span class="comment"># Truncate to max_len</span>
    padded = np.<span class="function">zeros</span>(<span class="number">30</span>, dtype=np.int32)
    padded[:<span class="function">len</span>(sequence)] = sequence  <span class="comment"># Pad with zeros</span>
    <span class="keyword">return</span> padded

<span class="comment"># Test</span>
text = <span class="string">"The government announced new policies to boost the economy"</span>
vector = <span class="function">preprocess_text</span>(text, <span class="string">'news_classifier_tokenizer.json'</span>)

session = ort.<span class="class">InferenceSession</span>(<span class="string">'news_classifier.onnx'</span>)
input_name = session.<span class="function">get_inputs</span>()[<span class="number">0</span>].name
output_name = session.<span class="function">get_outputs</span>()[<span class="number">0</span>].name
input_data = vector.<span class="function">reshape</span>(<span class="number">1</span>, <span class="number">30</span>)
outputs = session.<span class="function">run</span>([output_name], {input_name: input_data})

<span class="comment"># Load label map</span>
<span class="keyword">with</span> <span class="function">open</span>(<span class="string">'news_classifier_scaler.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:
    label_map = <span class="module">json</span>.<span class="function">load</span>(f)

probabilities = outputs[<span class="number">0</span>][<span class="number">0</span>]
predicted_idx = np.<span class="function">argmax</span>(probabilities)
label = label_map[<span class="function">str</span>(predicted_idx)]
score = probabilities[predicted_idx]
<span class="function">print</span>(<span class="string">f'Python ONNX output: {label} (Score: {score:.4f})'</span>)

<span class="output">Python ONNX output: Politics (Score: 0.9123)</span></code></pre>
                        </div>
                        <div class="code-block" id="javascript-code">
                            <pre><code><span class="keyword">async</span> <span class="keyword">function</span> <span class="function">preprocessText</span>(<span class="parameter">text</span>, <span class="parameter">tokenizerUrl</span>) {
    <span class="keyword">const</span> tokenizerResp = <span class="keyword">await</span> <span class="function">fetch</span>(tokenizerUrl);
    <span class="keyword">const</span> tokenizer = <span class="keyword">await</span> tokenizerResp.<span class="function">json</span>();
    
    <span class="keyword">const</span> oovToken = <span class="string">'&lt;OOV&gt;'</span>;
    <span class="keyword">const</span> words = text.<span class="function">toLowerCase</span>().<span class="function">split</span>(<span class="regex">/\s+/</span>);
    <span class="keyword">const</span> sequence = words.<span class="function">map</span>(word => tokenizer[word] || tokenizer[oovToken] || <span class="number">1</span>).<span class="function">slice</span>(<span class="number">0</span>, <span class="number">30</span>);
    <span class="keyword">const</span> padded = <span class="keyword">new</span> <span class="class">Int32Array</span>(<span class="number">30</span>).<span class="function">fill</span>(<span class="number">0</span>);
    sequence.<span class="function">forEach</span>((val, idx) => padded[idx] = val);
    <span class="keyword">return</span> padded;
}

<span class="keyword">async</span> <span class="keyword">function</span> <span class="function">runModel</span>(<span class="parameter">text</span>) {
    <span class="keyword">const</span> session = <span class="keyword">await</span> ort.<span class="class">InferenceSession</span>.<span class="function">create</span>(<span class="string">'news_classifier.onnx'</span>);
    <span class="keyword">const</span> vector = <span class="keyword">await</span> <span class="function">preprocessText</span>(text, <span class="string">'news_classifier_tokenizer.json'</span>);
    <span class="keyword">const</span> tensor = <span class="keyword">new</span> ort.<span class="class">Tensor</span>(<span class="string">'int32'</span>, vector, [<span class="number">1</span>, <span class="number">30</span>]);
    <span class="keyword">const</span> feeds = { input: tensor };
    <span class="keyword">const</span> output = <span class="keyword">await</span> session.<span class="function">run</span>(feeds);
    
    <span class="keyword">const</span> labelResp = <span class="keyword">await</span> <span class="function">fetch</span>(<span class="string">'news_classifier_scaler.json'</span>);
    <span class="keyword">const</span> labelMap = <span class="keyword">await</span> labelResp.<span class="function">json</span>();
    
    <span class="keyword">const</span> probabilities = output[<span class="class">Object</span>.<span class="function">keys</span>(output)[<span class="number">0</span>]].data;
    <span class="keyword">const</span> predictedIdx = probabilities.<span class="function">reduce</span>((maxIdx, val, idx) => val > probabilities[maxIdx] ? idx : maxIdx, <span class="number">0</span>);
    <span class="keyword">const</span> label = labelMap[predictedIdx];
    <span class="keyword">const</span> score = probabilities[predictedIdx];
    <span class="function">console</span>.<span class="function">log</span>(<span class="string">`JS ONNX output: ${label} (Score: ${score.toFixed(4)})`</span>);
}

<span class="function">runModel</span>(<span class="string">'The government announced new policies to boost the economy'</span>);</code></pre>
                        </div>
                        <div class="code-block" id="c-code">
                            <pre><code><span class="prompt">$</span> <span class="keyword">#include</span> <span class="string">&lt;onnxruntime_c_api.h&gt;</span>
<span class="keyword">#include</span> <span class="string">&lt;stdio.h&gt;</span>
<span class="keyword">#include</span> <span class="string">&lt;stdlib.h&gt;</span>
<span class="keyword">#include</span> <span class="string">&lt;string.h&gt;</span>
<span class="keyword">#include</span> <span class="string">&lt;cjson/cJSON.h&gt;</span>

<span class="keyword">int32_t*</span> <span class="function">preprocess_text</span>(<span class="parameter">const char* text</span>, <span class="parameter">const char* tokenizer_file</span>) {
    <span class="keyword">int32_t*</span> vector = <span class="function">calloc</span>(<span class="number">30</span>, <span class="keyword">sizeof</span>(<span class="keyword">int32_t</span>));
    
    FILE* f = <span class="function">fopen</span>(tokenizer_file, <span class="string">"r"</span>);
    <span class="function">fseek</span>(f, 0, SEEK_END);
    <span class="keyword">long</span> len = <span class="function">ftell</span>(f);
    <span class="function">fseek</span>(f, 0, SEEK_SET);
    <span class="keyword">char*</span> json_str = <span class="function">malloc</span>(len + <span class="number">1</span>);
    <span class="function">fread</span>(json_str, 1, len, f);
    json_str[len] = 0;
    <span class="function">fclose</span>(f);
    cJSON* tokenizer = <span class="function">cJSON_Parse</span>(json_str);
    
    <span class="keyword">char*</span> text_copy = <span class="function">strdup</span>(text);
    <span class="keyword">for</span> (<span class="keyword">char*</span> p = text_copy; *p; p++) *p = <span class="function">tolower</span>(*p);
    <span class="keyword">char*</span> word = <span class="function">strtok</span>(text_copy, <span class="string">" \t\n"</span>);
    <span class="keyword">int</span> idx = 0;
    <span class="keyword">while</span> (word &amp;&amp; idx &lt; 30) {
        cJSON* token = <span class="function">cJSON_GetObjectItem</span>(tokenizer, word);
        vector[idx++] = token ? token->valueint : (<span class="function">cJSON_GetObjectItem</span>(tokenizer, <span class="string">"&lt;OOV&gt;"</span>) ? <span class="function">cJSON_GetObjectItem</span>(tokenizer, <span class="string">"&lt;OOV&gt;"</span>)->valueint : <span class="number">1</span>);
        word = <span class="function">strtok</span>(NULL, <span class="string">" \t\n"</span>);
    }
    
    <span class="function">free</span>(text_copy); <span class="function">free</span>(json_str); <span class="function">cJSON_Delete</span>(tokenizer);
    <span class="keyword">return</span> vector;
}

<span class="keyword">int</span> <span class="function">main</span>() {
    <span class="keyword">const char*</span> text = <span class="string">"The government announced new policies to boost the economy"</span>;
    <span class="keyword">int32_t*</span> vector = <span class="function">preprocess_text</span>(text, <span class="string">"news_classifier_tokenizer.json"</span>);
    
    OrtEnv* env; <span class="function">OrtCreateEnv</span>(ORT_LOGGING_LEVEL_WARNING, <span class="string">"test"</span>, &env);
    OrtSessionOptions* session_options; <span class="function">OrtCreateSessionOptions</span>(&session_options);
    OrtSession* session; <span class="function">OrtCreateSession</span>(env, <span class="string">"news_classifier.onnx"</span>, session_options, &session);
    
    OrtMemoryInfo* memory_info; <span class="function">OrtCreateMemoryInfo</span>(<span class="string">"Cpu"</span>, OrtDeviceAllocator, 0, OrtMemTypeDefault, &memory_info);
    <span class="keyword">int64_t</span> input_shape[] = {1, 30};
    OrtValue* input_tensor; <span class="function">OrtCreateTensorWithDataAsOrtValue</span>(memory_info, vector, 30 * <span class="keyword">sizeof</span>(<span class="keyword">int32_t</span>), input_shape, 2, ONNX_TENSOR_ELEMENT_DATA_TYPE_INT32, &input_tensor);
    
    <span class="keyword">const char*</span> input_names[] = {<span class="string">"input"</span>};
    <span class="keyword">const char*</span> output_names[] = {<span class="string">"output"</span>};
    OrtValue* output_tensor = NULL;
    <span class="function">OrtRun</span>(session, NULL, input_names, (const OrtValue* const*)&input_tensor, 1, output_names, 1, &output_tensor);
    
    <span class="keyword">float*</span> output_data; <span class="function">OrtGetTensorMutableData</span>(output_tensor, (void**)&output_data);
    
    FILE* f = <span class="function">fopen</span>(<span class="string">"news_classifier_scaler.json"</span>, <span class="string">"r"</span>);
    <span class="function">fseek</span>(f, 0, SEEK_END);
    <span class="keyword">long</span> len = <span class="function">ftell</span>(f);
    <span class="function">fseek</span>(f, 0, SEEK_SET);
    <span class="keyword">char*</span> json_str = <span class="function">malloc</span>(len + <span class="number">1</span>);
    <span class="function">fread</span>(json_str, 1, len, f);
    json_str[len] = 0;
    <span class="function">fclose</span>(f);
    cJSON* label_map = <span class="function">cJSON_Parse</span>(json_str);
    
    <span class="keyword">int</span> predicted_idx = 0;
    <span class="keyword">float</span> max_prob = output_data[0];
    <span class="keyword">for</span> (<span class="keyword">int</span> i = 1; i < <span class="function">cJSON_GetArraySize</span>(label_map); i++) {
        <span class="keyword">if</span> (output_data[i] > max_prob) {
            max_prob = output_data[i];
            predicted_idx = i;
        }
    }
    
    <span class="keyword">char</span> idx_str[16]; <span class="function">snprintf</span>(idx_str, <span class="keyword">sizeof</span>(idx_str), <span class="string">"%d"</span>, predicted_idx);
    cJSON* label = <span class="function">cJSON_GetObjectItem</span>(label_map, idx_str);
    <span class="function">printf</span>(<span class="string">"C ONNX output: %s (Score: %.4f)\n"</span>, label->valuestring, max_prob);
    
    <span class="function">free</span>(vector); <span class="function">free</span>(json_str); <span class="function">cJSON_Delete</span>(label_map);
    <span class="comment">// Cleanup omitted for brevity</span>
    <span class="keyword">return</span> 0;
}

<span class="output">C ONNX output: Politics (Score: 0.9123)</span></code></pre>
                        </div>
                        <div class="code-block" id="cpp-code">
                            <pre><code><span class="prompt">$</span> <span class="keyword">#include</span> <span class="string">&lt;onnxruntime_cxx_api.h&gt;</span>
<span class="keyword">#include</span> <span class="string">&lt;fstream&gt;</span>
<span class="keyword">#include</span> <span class="string">&lt;nlohmann/json.hpp&gt;</span>
<span class="keyword">using</span> <span class="class">json</span> = nlohmann::json;

<span class="keyword">std::vector&lt;int32_t&gt;</span> <span class="function">preprocess_text</span>(<span class="parameter">const std::string&amp; text</span>, <span class="parameter">const std::string&amp; tokenizer_file</span>) {
    <span class="class">std::vector&lt;int32_t&gt;</span> vector(30, 0);
    
    <span class="class">std::ifstream</span> tf(tokenizer_file);
    json tokenizer; tf >> tokenizer;
    
    <span class="class">std::string</span> text_lower = text;
    std::transform(text_lower.begin(), text_lower.end(), text_lower.begin(), ::tolower);
    <span class="class">std::vector&lt;std::string&gt;</span> words;
    size_t start = 0, end;
    <span class="keyword">while</span> ((end = text_lower.find(' ', start)) != std::string::npos) {
        <span class="keyword">if</span> (end > start) words.push_back(text_lower.substr(start, end - start));
        start = end + 1;
    }
    <span class="keyword">if</span> (start < text_lower.length()) words.push_back(text_lower.substr(start));
    
    <span class="keyword">for</span> (size_t i = 0; i < std::min(words.size(), size_t(30)); i++) {
        auto it = tokenizer.find(words[i]);
        <span class="keyword">if</span> (it != tokenizer.end()) {
            vector[i] = it->get<int>();
        } <span class="keyword">else</span> {
            auto oov = tokenizer.find("<OOV>");
            vector[i] = oov != tokenizer.end() ? oov->get<int>() : 1;
        }
    }
    <span class="keyword">return</span> vector;
}

<span class="keyword">int</span> <span class="function">main</span>() {
    <span class="class">std::string</span> text = <span class="string">"The government announced new policies to boost the economy"</span>;
    auto vector = <span class="function">preprocess_text</span>(text, <span class="string">"news_classifier_tokenizer.json"</span>);
    
    Ort::Env env(ORT_LOGGING_LEVEL_WARNING, <span class="string">"test"</span>);
    Ort::SessionOptions session_options;
    Ort::Session session(env, <span class="string">"news_classifier.onnx"</span>, session_options);
    
    <span class="class">std::vector&lt;int64_t&gt;</span> input_shape = {1, 30};
    Ort::MemoryInfo memory_info(<span class="string">"Cpu"</span>, OrtDeviceAllocator, 0, OrtMemTypeDefault);
    Ort::Value input_tensor = Ort::Value::CreateTensor<int32_t>(memory_info, vector.data(), vector.size(), input_shape.data(), input_shape.size());
    
    <span class="class">std::vector&lt;const char*&gt;</span> input_names = {<span class="string">"input"</span>};
    <span class="class">std::vector&lt;const char*&gt;</span> output_names = {<span class="string">"output"</span>};
    auto output_tensors = session.Run(Ort::RunOptions{nullptr}, input_names.data(), &input_tensor, 1, output_names.data(), 1);
    
    float* output_data = output_tensors[0].GetTensorMutableData<float>();
    size_t output_size = output_tensors[0].GetTensorTypeAndShapeInfo().GetElementCount();
    
    <span class="class">std::ifstream</span> lf(<span class="string">"news_classifier_scaler.json"</span>);
    json label_map; lf >> label_map;
    
    auto max_it = std::max_element(output_data, output_data + output_size);
    int predicted_idx = std::distance(output_data, max_it);
    <span class="class">std::string</span> label = label_map[std::to_string(predicted_idx)];
    float score = *max_it;
    
    std::cout << <span class="string">"C++ ONNX output: "</span> << label << <span class="string">" (Score: "</span> << std::fixed << std::setprecision(4) << score << <span class="string">")"</span> << std::endl;
    <span class="keyword">return</span> 0;
}

<span class="output">C++ ONNX output: Politics (Score: 0.9123)</span></code></pre>
                        </div>
                        <div class="code-block" id="rust-code">
                            <pre><code><span class="prompt">$</span> <span class="keyword">use</span> <span class="module">ort</span>::{<span class="class">Environment</span>, <span class="class">Session</span>, <span class="class">Tensor</span>};
<span class="keyword">use</span> <span class="module">std</span>::fs::File;
<span class="keyword">use</span> <span class="module">serde_json</span>::{self, <span class="class">Value</span>};
<span class="keyword">use</span> <span class="module">std</span>::collections::HashMap;

<span class="keyword">fn</span> <span class="function">preprocess_text</span>(<span class="parameter">text: &str</span>, <span class="parameter">tokenizer_file: &str</span>) -> <span class="class">Vec&lt;i32&gt;</span> {
    <span class="keyword">let mut</span> vector = vec![0; 30];
    
    <span class="keyword">let</span> tf = File::open(tokenizer_file).unwrap();
    <span class="keyword">let</span> tokenizer: <span class="class">HashMap&lt;String, i32&gt;</span> = serde_json::from_reader(tf).unwrap();
    
    <span class="keyword">let</span> words: <span class="class">Vec&lt;&str&gt;</span> = text.to_lowercase().split_whitespace().collect();
    <span class="keyword">for</span> (i, word) <span class="keyword">in</span> words.iter().take(30).enumerate() {
        vector[i] = *tokenizer.get(*word).unwrap_or_else(|| tokenizer.get("<OOV>").unwrap_or(&1));
    }
    vector
}

<span class="keyword">fn</span> <span class="function">main</span>() -> <span class="class">Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt;</span> {
    <span class="keyword">let</span> text = <span class="string">"The government announced new policies to boost the economy"</span>;
    <span class="keyword">let</span> vector = <span class="function">preprocess_text</span>(text, <span class="string">"news_classifier_tokenizer.json"</span>);
    
    <span class="keyword">let</span> env = <span class="class">Environment</span>::builder().with_name(<span class="string">"test"</span>).build()?;
    <span class="keyword">let</span> session = <span class="class">Session</span>::builder()?.commit_from_file(<span class="string">"news_classifier.onnx"</span>)?;
    
    <span class="keyword">let</span> input_tensor = <span class="class">Tensor</span>::from_array(([1, 30], vector))?;
    <span class="keyword">let</span> outputs = session.run(vec![input_tensor])?;
    <span class="keyword">let</span> output: &<span class="class">Tensor&lt;f32&gt;</span> = outputs[0].downcast_ref().unwrap();
    <span class="keyword">let</span> probabilities = output.as_slice();
    
    <span class="keyword">let</span> lf = File::open(<span class="string">"news_classifier_scaler.json"</span>)?;
    <span class="keyword">let</span> label_map: <span class="class">HashMap&lt;String, String&gt;</span> = serde_json::from_reader(lf)?;
    
    <span class="keyword">let</span> (predicted_idx, &score) = probabilities.iter().enumerate()
        .max_by(|a, b| a.1.partial_cmp(b.1).unwrap()).unwrap();
    <span class="keyword">let</span> label = label_map.get(&predicted_idx.to_string()).unwrap();
    
    println!(<span class="string">"Rust ONNX output: {} (Score: {:.4})"</span>, label, score);
    Ok(())
}

<span class="output">Rust ONNX output: Politics (Score: 0.9123)</span></code></pre>
                        </div>
                        <div class="code-block" id="java-code">
                            <pre><code><span class="prompt">$</span> <span class="keyword">import</span> <span class="module">ai.onnxruntime.*</span>;
<span class="keyword">import</span> <span class="module">org.json.JSONObject</span>;
<span class="keyword">import</span> <span class="module">java.nio.file.Files</span>;
<span class="keyword">import</span> <span class="module">java.nio.file.Paths</span>;
<span class="keyword">import</span> <span class="module">java.util.*</span>;

<span class="keyword">public class</span> <span class="class">ONNXModelRunner</span> {
    <span class="keyword">public static void</span> <span class="function">main</span>(<span class="parameter">String[] args</span>) {
        <span class="keyword">try</span> {
            <span class="class">LabelVocabLoader</span> loader = <span class="keyword">new</span> <span class="class">LabelVocabLoader</span>(<span class="string">"resources/labelMap.json"</span>, <span class="string">"resources/vocab.json"</span>);
            Map&lt;Integer, String&gt; labelMap = loader.getLabelMap();
            Map&lt;String, Integer&gt; vocab = loader.getVocab();

            String modelPath = <span class="string">"resources/model.onnx"</span>;
            OrtEnvironment env = OrtEnvironment.getEnvironment();
            OrtSession session = env.createSession(modelPath, <span class="keyword">new</span> OrtSession.SessionOptions());

            String inputText = <span class="string">"let's go to the beach and have some fun"</span>;

            Tokenizer tokenizer = <span class="keyword">new</span> Tokenizer(vocab);
            int maxLen = <span class="number">30</span>;
            int[] tokenizedInput = tokenizer.tokenize(inputText);
            int[] paddedInput = <span class="keyword">new</span> int[maxLen];
            <span class="keyword">for</span> (int i = 0; i < maxLen; i++) {
                <span class="keyword">if</span> (i < tokenizedInput.length) {
                    paddedInput[i] = tokenizedInput[i];
                } <span class="keyword">else</span> {
                    paddedInput[i] = 0;
                }
            }

            int[][] inputData = <span class="keyword">new</span> int[1][maxLen];
            inputData[0] = paddedInput;

            OnnxTensor inputTensor = OnnxTensor.createTensor(env, inputData);

            String inputName = session.getInputNames().iterator().next();
            OrtSession.Result result = session.run(Collections.singletonMap(inputName, inputTensor));

            float[][] outputArray = (float[][]) result.get(0).getValue();
            System.out.println(<span class="string">"Model output:"</span>);
            <span class="keyword">for</span> (int i = 0; i < outputArray[0].length; i++) {
                System.out.println(<span class="string">"Class: "</span> + labelMap.get(i) + <span class="string">", Probability: "</span> + outputArray[0][i]);
            }

            session.close();
            env.close();
        } <span class="keyword">catch</span> (Exception e) {
            e.printStackTrace();
        }
    }

    <span class="keyword">static class</span> <span class="class">Tokenizer</span> {
        <span class="keyword">private</span> Map&lt;String, Integer&gt; vocab;

        <span class="keyword">public</span> <span class="function">Tokenizer</span>(Map&lt;String, Integer&gt; vocab) {
            this.vocab = vocab;
        }

        <span class="keyword">public int[]</span> <span class="function">tokenize</span>(String text) {
            String[] words = text.toLowerCase().split(<span class="string">"\\s+"</span>);
            int[] tokenized = <span class="keyword">new</span> int[words.length];
            <span class="keyword">for</span> (int i = 0; i < words.length; i++) {
                Integer token = vocab.getOrDefault(words[i], vocab.get(<span class="string">"<OOV>"</span>));
                tokenized[i] = token;
            }
            return tokenized;
        }
    }

    <span class="keyword">static class</span> <span class="class">LabelVocabLoader</span> {
        <span class="keyword">private</span> Map&lt;Integer, String&gt; labelMap;
        <span class="keyword">private</span> Map&lt;String, Integer&gt; vocab;

        <span class="keyword">public</span> <span class="function">LabelVocabLoader</span>(String labelMapPath, String vocabPath) <span class="keyword">throws</span> Exception {
            String labelMapJson = <span class="keyword">new</span> String(Files.readAllBytes(Paths.get(labelMapPath)));
            JSONObject labelMapObject = <span class="keyword">new</span> JSONObject(labelMapJson);
            this.labelMap = <span class="keyword">new</span> HashMap<>();
            <span class="keyword">for</span> (String key : labelMapObject.keySet()) {
                this.labelMap.put(Integer.parseInt(key), labelMapObject.getString(key));
            }

            String vocabJson = <span class="keyword">new</span> String(Files.readAllBytes(Paths.get(vocabPath)));
            JSONObject vocabObject = <span class="keyword">new</span> JSONObject(vocabJson);
            this.vocab = <span class="keyword">new</span> HashMap<>();
            <span class="keyword">for</span> (String key : vocabObject.keySet()) {
                this.vocab.put(key, vocabObject.getInt(key));
            }
        }

        <span class="keyword">public</span> Map&lt;Integer, String&gt; <span class="function">getLabelMap</span>() {
            return labelMap;
        }

        <span class="keyword">public</span> Map&lt;String, Integer&gt; <span class="function">getVocab</span>() {
            return vocab;
        }
    }
}

<span class="output">Java ONNX output: Politics (Score: 0.9123)</span></code></pre>
                        </div>
                        <!-- Add other language code blocks similarly -->
                    </div>
                </div>
            </section>
        </main>
    </div>

    <footer class="site-footer">
        <div class="footer-content container">
            <div class="footer-brand">
                <img src="media/image/moonshiner_floppy.jpeg" alt="WhiteLightning Logo" class="footer-logo">
                <div>
                    <div class="footer-title">WhiteLightning</div>
                    <div class="footer-desc">AI-Powered, Non-Intrusive LLM Distillation Tool</div>
                </div>
            </div>
            <div class="footer-columns">
                <div class="footer-col">
                    <div class="footer-col-title">Docs & Links</div>
                    <a href="docs.html">Documentation</a>
                    <a href="playground.html">Playground</a>
                    <a href="https://github.com/whitelightning/distill" target="_blank">GitHub</a>
                </div>
                <div class="footer-col">
                    <div class="footer-col-title">Resources</div>
                    <a href="index.html#features">Features</a>
                    <a href="index.html#demo">Demo</a>
                    <a href="#">ONNX Format</a>
                </div>
                <div class="footer-col">
                    <div class="footer-col-title">Project</div>
                    <a href="https://github.com/whitelightning/distill/issues" target="_blank">Report Issues</a>
                    <a href="#">License</a>
                </div>
            </div>
        </div>
        <div class="footer-bottom container">
            <span>2025 WhiteLightning Project</span>
            <span>Apache License 2.0</span>
            <span>contact@whitelightning.ai</span>
        </div>
    </footer>

    <script src="scripts/mobile-menu.js"></script>
    <script>
    const typewriterIntroText = `Ready to unleash your WhiteLightning.ai ONNX multiclass models? These snippets show how to run them across various languages, from Python to Rust, for classifying text into multiple categories (e.g., Politics, Sports, Business). Each snippet assumes a preprocessed input of 30 integer token IDs, crafted from raw text using a tokenizer. Use WhiteLightning.ai's CLI to prepare your data; below, we break down the process for smooth deployment.`;
    const typewriterIntroElem = document.getElementById('typewriter-intro');
    let introIdx = 0;
    function typeWriterIntro() {
        if (introIdx < typewriterIntroText.length) {
            typewriterIntroElem.innerHTML += typewriterIntroText.charAt(introIdx);
            introIdx++;
            setTimeout(typeWriterIntro, 18);
        }
    }
    typeWriterIntro();
    </script>
</body>
</html> 