<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WhiteLightning Documentation</title>
  <link rel="icon" type="image/png" href="media/image/favicons-f07016ef02d695ba85dee5ffd3b42f39(pr-cy.ru)/favicon-32x32.png" />
  <link rel="stylesheet" href="styles/docs.css">
</head>
<body>
  <header class="wl-header">
    <div class="logo">
      <img src="media/image/moonshiner_floppy.jpeg" alt="WhiteLightning Logo">
      <h1><a href="/" style="text-decoration: none;letter-spacing: 0px; color: inherit; ">White<span>Lightning</span></a></h1>
    </div>
    <div class="hamburger">
      <span></span>
      <span></span>
      <span></span>
    </div>
    <nav class="desktop-nav">
      <ul>
        <li class="dropdown">
          <a href="">Introduction & Examples</a>
          <ul class="dropdown-menu">
            <li><a id="plgr_btn" href="/getting-started">Getting Started</a></li>
            <li><a href="/prompt-examples">Prompt Examples</a></li>      
          </ul>
        </li>
        <li class="dropdown">
          <a href="">Model Setup & Configuration</a>
          <ul class="dropdown-menu">
            <li><a href="/binary-setup">Binary Setup</a></li>
            <li><a href="/multiclass-setup">Multiclass Setup</a></li>
          </ul>
        </li>
        <li class="dropdown">
          <a href="">Using & Applying Your Model</a>
          <ul class="dropdown-menu">
            <li><a href="/binary-running">Binary Running</a></li>
            <li><a href="/multiclass-running">Multiclass Running</a></li>
            <li><a href="/mobile-deployment">Mobile Deployment</a></li>
            <li><a href="/playground">Playground</a></li>
          </ul>
        </li>
        <li><a href="https://github.com/volodymyrparanyak/whitelightning.ai" target="_blank">GitHub</a></li>
      </ul>
    </nav>
    <nav class="mobile-nav">
      <ul>
        <li class="mobile-section-header">Introduction & Examples</li>
        <li><a id="plgr_btn" href="/getting-started">Getting Started</a></li>
        <li><a href="/prompt-examples">Prompt Examples</a></li>
        
        <li class="mobile-section-header">Model Setup & Configuration</li>
        <li><a href="/binary-setup">Binary Setup</a></li>
        <li><a href="/multiclass-setup">Multiclass Setup</a></li>
        
        <li class="mobile-section-header">Using & Applying Your Model</li>
        <li><a href="/binary-running">Binary Running</a></li>
        <li><a href="/multiclass-running">Multiclass Running</a></li>
        <li><a href="/mobile-deployment">Mobile Deployment</a></li>
        <li><a href="/playground">Playground</a></li>
      </ul>
    </nav>
  </header>

  <div class="docs-container">
    <!-- <div class="docs-sidebar">
      <nav class="docs-nav">
        <ul>
          <li><a href="docs.html" class="active">Overview</a>
            <ul style="margin-left:1.2em;">
              <li><a href="docs.html#what-is-llm">What is LLM Distillation?</a></li>
              <li><a href="docs.html#why-onnx">Why ONNX?</a></li>
              <li><a href="docs.html#features">Key Features</a></li>
              <li><a href="docs.html#quick-start">Quick Start</a></li>
              <li><a href="docs.html#documentation">Deployment Guide</a></li>
            </ul>
          </li>
          <li><a href="#model-types">Model Types</a>
            <ul style="margin-left:1.2em;">
              <li><a href="binary-classifier.html">Binary Classifier</a></li>
              <ul style="margin-left:1.2em;">
                  <li><a href="running_bnr.html">Running</a></li>
                </ul>
              <li><a href="multiclass-classifier.html">Multiclass Classifier</a>
                <ul style="margin-left:1.2em;">
                  <li><a href="running_mlt.html">Running</a></li>
                </ul>
                <ul style="margin-left:1.2em;">
                  <li><a href="demo_mlt.html">Demos</a></li>
                </ul>
              </li>
            </ul>
          </li>
          
        </ul>
      </nav>
    </div> -->

    <main class="docs-content">
      <section id="introduction">
        <h1><span>WhiteLightning</span> - LLM Distillation Tool</h1>
        <div class="features-grid">
          <div class="feature-card large-text">
            
            <p>WhiteLightning is a powerful tool designed to distill large language models (LLMs) into lightweight, efficient text classifiers. By leveraging advanced techniques, it simplifies the process of creating text classifiers that can run anywhere, from cloud environments to edge devices, using the ONNX format for cross-platform compatibility.</p>
          </div>
        </div>
        
        <!-- <div class="logo-container">
          <img src="media/image/moonshiner_floppy.jpeg" alt="Moonshiner" class="logo-image">
        </div> -->

        <div class="demo-container">
            <div class="terminal-header">
              <div class="terminal-circle red"></div>
              <div class="terminal-circle yellow"></div>
              <div class="terminal-circle green"></div>
            </div>
            <div class="terminal-content">
              <p>
                <!-- <span class="prompt">$ </span> -->
                <span class="user-input full-text">whitelightning identify toxic comments in online discussions</span>
                <span class="user-input short-text"> WL identify toxic comments!</span>
              </p>
              <p>
                <span class="ai-response full-text"><span class="wl-label">WhiteLightning &gt;</span> I'll help you create a binary classifier for toxic comments detection.</span>
                <span class="ai-response short-text">Creating a binary classifier...</span>
              </p>
              <p>
                <span class="ai-response full-text"><span class="wl-label">WhiteLightning &gt;</span> First, I'll generate synthetic training data using LLM...</span>
                <span class="ai-response short-text">Generating synthetic data...</span>
              </p>
              <p>
                <span class="ai-response full-text"><span class="wl-label">WhiteLightning &gt;</span> Created 1000 examples (500 spam, 500 ham)</span>
                <span class="ai-response short-text">Created 1000 examples</span>
              </p>
              <p>
                <span class="ai-response full-text"><span class="wl-label">WhiteLightning &gt;</span> Training lightweight classifier model...</span>
                <span class="ai-response short-text">Training model...</span>
              </p>
              <p>
                <span class="ai-response full-text"><span class="wl-label">WhiteLightning &gt;</span> Model trained successfully. Accuracy: 94.2%</span>
                <span class="ai-response short-text">Model trained. Accuracy: 94.2%</span>
              </p>
              <p>
                <span class="ai-response full-text"><span class="wl-label">WhiteLightning &gt;</span> Saved model to toxic_comments_classifier.onnx (2.1MB)</span>
                <span class="ai-response short-text">Model saved</span>
              </p>
              <!-- <p><span class="prompt">$ </span></p> -->
            </div>
        </div>
      </section>

      <section id="what-is-llm">
        <!-- <h2>What is LLM Distillation?</h2> -->
        <div class="features-grid">
          <div class="feature-card large-text">
            <span class="feature-icon">üß†</span>
            <h3>What is LLM Distillation?</h3>
            <p>LLM distillation is the process of transforming large, complex language models into smaller, task-specific models. WhiteLightning focuses on text classification, enabling users to create efficient classifiers for various use cases. This approach ensures high performance while significantly reducing computational requirements.</p>
          </div>
        </div>
      </section>

      <section id="why-onnx">
        <!-- <h2>Why ONNX?</h2> -->
        <div class="features-grid">
          <div class="feature-card large-text">
            <span class="feature-icon">üîÑ</span>
            <h3>Why ONNX?</h3>
            <p>WhiteLightning uses ONNX (Open Neural Network Exchange) to export trained models, making them deployable across a wide range of platforms and programming languages. With ONNX, you can run your models in Python, JavaScript, C++, Rust, and more, ensuring flexibility and scalability for your applications.</p>
          </div>
        </div>
      </section>

      <section id="features">
        <h2>Key Features</h2>
        <div class="features-grid">
          <div class="feature-card">
            <span class="feature-icon">üî¢</span>
            <h3>Multiple Model Types</h3>
            <p>Support for binary and multiclass classification with different activation types</p>
          </div>
          <div class="feature-card">
            <span class="feature-icon">üåê</span>
            <h3>Cross-Platform Deployment</h3>
            <p>Export models to ONNX for use in diverse environments</p>
          </div>
          <div class="feature-card">
            <span class="feature-icon">‚ö°</span>
            <h3>Lightweight and Fast</h3>
            <p>Optimized for performance with minimal resource usage</p>
          </div>
          <div class="feature-card">
            <span class="feature-icon">üîß</span>
            <h3>Customizable</h3>
            <p>Supports multiple machine learning frameworks (TensorFlow, PyTorch, Scikit-learn)</p>
          </div>
          <div class="feature-card">
            <span class="feature-icon">üåç</span>
            <h3>Multilingual Support</h3>
            <p>Generate training data in multiple languages</p>
          </div>
          <div class="feature-card">
            <span class="feature-icon">ü§ñ</span>
            <h3>Automatic Configuration</h3>
            <p>Smart prompt generation and refinement based on your task</p>
          </div>
        </div>
      </section>

      <section id="model-types">
        <h2>Model Types</h2>
        <div class="models-grid">
          <div class="model-card" id="binary-classifier">
            <h3>Binary Classifier</h3>
            <p>Simple yes/no or true/false classification with probability output for single class. Ideal for sentiment analysis, spam detection, and content moderation.</p>
            <a href="/binary-setup" class="button">Learn More</a>
          </div>
          <!-- <div class="model-card">
            <h3>Multiclass Sigmoid</h3>
            <p>Multi-label classification with independent class probabilities. Multiple classes can be active simultaneously. Ideal for topic tagging, emotion detection, and content categorization.</p>
            <a href="multiclass-classifier.html" class="button">Learn More</a>
          </div> -->
          <div class="model-card" id="multiclass-classifier">
            <h3>Multiclass Classifier</h3>
            <p>Single-label classification with mutually exclusive class probabilities.Ideal for news categorization, intent classification, and language detection.</p>
            <a href="/multiclass-setup" class="button">Learn More</a>
          </div>
        </div>
      </section>

      <section id="quick-start">
        <h2>Quick Start</h2>
        <div class="quick-steps">
          <div class="quick-step">
            <p>Install dependencies:</p>
            <div class="code-block">
              <div class="terminal-header">
                <div class="terminal-circle red"></div>
                <div class="terminal-circle yellow"></div>
                <div class="terminal-circle green"></div>
              </div>
              <div class="terminal-content">
                <code>pip install -r requirements/base.txt</code>
              </div>
            </div>
          </div>
          <div class="quick-step">
            <p>Set up your environment:</p>
            <div class="code-block">
              <div class="terminal-header">
                <div class="terminal-circle red"></div>
                <div class="terminal-circle yellow"></div>
                <div class="terminal-circle green"></div>
              </div>
              <div class="terminal-content">
                <code>Edit .env with your API keys</code>
              </div>
            </div>
          </div>
          <div class="quick-step">
            <p>Run the classifier agent:</p>
            <div class="code-block">
              <div class="terminal-header">
                <div class="terminal-circle red"></div>
                <div class="terminal-circle yellow"></div>
                <div class="terminal-circle green"></div>
              </div>
              <div class="terminal-content">
                <code>python -m text_classifier.agent -p</code>
                <code>"Your classification task description"</code>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section id="documentation">
        <h2>Deployment Guide</h2>
        <div class="models-grid">
          <div class="model-card">
            <h3>Model Deployment</h3>
            <p>Learn how to deploy your ONNX models across different platforms and environments for maximum flexibility.</p>
            <a href="/multiclass-running" class="button">Multiclass</a>
            <a href="/binary-running" class="button">Binary</a>
            <a href="/mobile-deployment" class="button">Demos</a>
          </div>
          <!-- <div class="model-card">
            <h3>API Reference</h3>
            <p>Explore the full API documentation for integrating and extending WhiteLightning in your projects.</p>
            <a href="#" class="button">View API Docs</a>
          </div> -->
        </div>
      </section>

      <!-- <section id="contributing">
        <h2>Contributing</h2>
        <p>We welcome contributions! Please see our <a href="#" class="neon-link">Contributing Guide</a> for details.</p>
        <p>This project is licensed under the MIT License - see the <a href="#" class="neon-link">LICENSE</a> file for details.</p>
      </section> -->
    </main>
  </div>

  <footer class="site-footer">
    <div class="footer-content container">
      <div class="footer-brand">
        <img src="media/image/moonshiner_floppy.jpeg" alt="WhiteLightning Logo" class="footer-logo">
        <div>
          <div class="footer-title">WhiteLightning</div>
          <div class="footer-desc">Create Edge‚ÄëReady AI in One Line No Data Required</div>
        </div>
      </div>
      <div class="footer-columns">
        <div class="footer-col">
          <div class="footer-col-title">Docs & Links</div>
          <a href="docs">Documentation</a>
          <a href="playground">Playground</a>
          <a href="https://github.com/volodymyrparanyak/whitelightning.ai" target="_blank">GitHub</a>
        </div>
        <div class="footer-col">
          <div class="footer-col-title">Resources</div>
          <a href="docs#features">Features</a>
          <a href="demo_mlt">Demo</a>
          <!-- <a href="#">ONNX Format</a> -->
        </div>
        <div class="footer-col">
          <div class="footer-col-title">Project</div>
          <a href="https://github.com/volodymyrparanyak/whitelightning.ai/pulls" target="_blank">Report Issues</a>
          <a href="https://github.com/volodymyrparanyak/whitelightning.ai/blob/alpha-0.0.1/LICENSE" target="_blank">License</a>
        </div>
      </div>
    </div>
    <div class="footer-bottom container">
      <span>2025 WhiteLightning Project</span>
      <span>Apache License 2.0</span>
      <span>contact@whitelightning.ai</span>
    </div>
  </footer>
  <script src="scripts/mobile-menu.js"></script>
</body>
</html> 